{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c6391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\.conda\\envs\\pytorch_envs\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\nguye\\.conda\\envs\\pytorch_envs\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import onnx\n",
    "import torch\n",
    "import tensorflow as tf \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afc4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/nguye/OneDrive/Desktop/ai4theblind/Resnet-ssd/')\n",
    "import numpy as np\n",
    "import torch\n",
    "from transform import SSDTransformer\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from Default_boxes import generate_dboxes\n",
    "from encoder import Encoder\n",
    "from models import SSD, ResNet\n",
    "import pyttsx3\n",
    "import time\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae113d",
   "metadata": {},
   "source": [
    "[Tham khảo từ bài viết](https://viblo.asia/p/huong-dan-convert-pytorch-sang-tf-lite-YWOZrV8RZQ0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0477bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_torch_to_onnx(onnx_path, image_path, model=None, torch_path=None):\n",
    "    \"\"\"\n",
    "        Coverts Pytorch model file to ONNX\n",
    "        :param torch_path: Torch model path to load\n",
    "        :param onnx_path: ONNX model path to save\n",
    "        :param image_path: Path to test image to use in export progress\n",
    "    \"\"\"\n",
    "    if torch_path is not None:\n",
    "        pytorch_model = get_torch_model(torch_path)\n",
    "    else:\n",
    "        pytorch_model = model\n",
    "    \n",
    "    torch_image = get_example_input(image_path)\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model = pytorch_model,\n",
    "        args = torch_image,\n",
    "        f = onnx_path,\n",
    "        verbose = False,\n",
    "        export_params=True,\n",
    "        do_constant_folding = False,\n",
    "        input_names = ['input'],\n",
    "        opset_version = 10,\n",
    "        output_names = ['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99dfe57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSD(backbone=ResNet())\n",
    "checkpoint = torch.load(config.pretrained_model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# if torch.cuda.is_available():\n",
    "#         model.cuda()\n",
    "model.eval()\n",
    "dboxes = generate_dboxes()\n",
    "transformer = SSDTransformer(dboxes, (300, 300), val=True)\n",
    "def get_example_input(image_file):\n",
    "    \"\"\"\n",
    "        Load image from disk and converts to compatible shape\n",
    "        :param image_file: Path to single image file\n",
    "        :return: Orginal image, numpy.ndarray instance image, torch.Tensor image\n",
    "    \"\"\"\n",
    "    frame = cv2.imread(image_file)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame, _, _, _ = transformer(frame, None, torch.zeros(1, 4), torch.zeros(1))\n",
    "    image = frame.unsqueeze(dim=0)\n",
    "#     image = image.cuda()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1d1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSD(backbone=ResNet())\n",
    "checkpoint = torch.load(config.pretrained_model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# if torch.cuda.is_available():\n",
    "#         model.cuda()\n",
    "model.eval()\n",
    "dboxes = generate_dboxes()\n",
    "transformer = SSDTransformer(dboxes, (300, 300), val=True)\n",
    "\n",
    "\n",
    "onnx_model_path ='model.onnx'\n",
    "image_path = \"../Resnet-ssd/data_test/000104.jpg\"\n",
    "\n",
    "convert_torch_to_onnx(onnx_model_path,image_path, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75035111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onnx_to_tf(onnx_path, tf_path):\n",
    "    \"\"\"\n",
    "        Converts ONNX model to TF 2.X saved file\n",
    "        :param onnx_path: ONNX model path to load\n",
    "        :param tf_path: TF model path to save\n",
    "    \"\"\"\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    tf_rep = prepare(onnx_model)  #Prepare TF representation\n",
    "    tf_rep.export_graph(tf_path)  #Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66925838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "onnx_path =\"../Resnet-ssd/model.onnx\"\n",
    "tf_path = \"model_tf\"\n",
    "\n",
    "convert_onnx_to_tf(onnx_path, tf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be412019",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_path =\"../Resnet-ssd/model_tf/\"\n",
    "image_test_path = \"../Resnet-ssd/data_test/000104.jpg\"\n",
    "\n",
    "input_tensor = get_example_input(image_test_path) \n",
    "\n",
    "model = tf.saved_model.load(tf_model_path)\n",
    "model.trainable = False\n",
    "\n",
    "out = model(**{'input':input_tensor})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162a5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_to_tflite(tf_path, tf_lite_path):\n",
    "    \"\"\"\n",
    "        Converts TF saved model into TFLite model\n",
    "        :param tf_path: TF saved model path to load\n",
    "        :param tf_lite_path: TFLite model path to save\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "    tflite_model  = converter.convert()\n",
    "    with open(tf_lite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        \n",
    "\n",
    "tf_model_path = \"../Resnet-ssd/model_tf\"\n",
    "tflite_model_path =\"model.tflite\"\n",
    "\n",
    "convert_tf_to_tflite(tf_model_path, tflite_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887c6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
