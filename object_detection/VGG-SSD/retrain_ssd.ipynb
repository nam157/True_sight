{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,cv2,torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0,'C:/Users/nguye/OneDrive/Desktop/2_object_detection')\n",
    "\n",
    "from Inference.inference import show_predict\n",
    "from models.model import SSD\n",
    "from  lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader.make_datapath import make_datapath_list\n",
    "from data.data_loader.dataset import MyDataset, my_collate_fn\n",
    "from data.data_loader.transform import DataTransform\n",
    "from data.data_loader.extract_inform_annotation import Anno_xml\n",
    "from models.model import SSD\n",
    "from multiboxloss import MultiBoxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print(\"device:\", device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\",  \"boat\", \"bottle\", \n",
    "    \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "    \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "cfg = {\n",
    "    \"num_classes\": 21, #VOC data include 20 class + 1 background class\n",
    "    \"input_size\": 300, #SSD300\n",
    "    \"bbox_aspect_num\": [4, 6, 6, 6, 4, 4], # Tỷ lệ khung hình cho source1->source6`\n",
    "    \"feature_maps\": [38, 19, 10, 5, 3, 1],\n",
    "    \"steps\": [8, 16, 32, 64, 100, 300], # Size of default box\n",
    "    \"min_size\": [30, 60, 111, 162, 213, 264], # Size of default box\n",
    "    \"max_size\": [60, 111, 162, 213, 264, 315], # Size of default box\n",
    "    \"aspect_ratios\": [[2], [2,3], [2,3], [2,3], [2], [2]]\n",
    "}\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "weights = 'C:/Users/nguye/OneDrive/Desktop/2_object_detection/data/weights/ssd300_mAP_77.43_v2.pth'\n",
    "net = SSD(phase=\"train\", cfg=cfg)\n",
    "net_weights = torch.load(weights, map_location={\"cuda:0\":\"cpu\"})\n",
    "net.load_state_dict(net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (vgg): ModuleList(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (34): ReLU(inplace=True)\n",
       "  )\n",
       "  (extras): ModuleList(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (L2Norm): L2Norm()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../2_object_detection/data/VOC2007\"\n",
    "\n",
    "#Load path img and annotations\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(root_path)\n",
    "\n",
    "#load dataset\n",
    "train_dataset = MyDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "val_dataset = MyDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size, shuffle=False, collate_fn=my_collate_fn)\n",
    "dataloader_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MultiBoxLoss(jaccard_threshold=0.5, neg_pos=4, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epochs):\n",
    "    # move network to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "    for epoch in range(num_epochs+1):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"---\"*20)\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "                print(\"(Training)\")\n",
    "            else:\n",
    "                #10 epoch minh se kiem dinh 1 lan\n",
    "                if (epoch+1) % 10 == 0:\n",
    "                    net.eval() \n",
    "                    print(\"---\"*10)\n",
    "                    print(\"(Validation)\")\n",
    "                else:\n",
    "                    continue\n",
    "            for images, targets in dataloader_dict[phase]:\n",
    "                # move to GPU\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # init optimizer\n",
    "                optimizer.zero_grad()\n",
    "                #forward: dua anh vao trong mang cua minh\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = net(images)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    print(criterion(outputs, targets))\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # calculate gradient\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step() # update parameters\n",
    "\n",
    "                        if (iteration % 10) == 0:\n",
    "                            t_iter_end = time.time()\n",
    "                            duration = t_iter_end - t_iter_start\n",
    "                            print(\"Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_end = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {} || epoch_train_loss: {:.4f} || Epoch_val_loss: {:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))           \n",
    "        print(\"Duration: {:.4f} sec\".format(t_epoch_end - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\": epoch+1, \"train_loss\": epoch_train_loss, \"val_loss\": epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"./data/ssd_logs.csv\")\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), \"../../2_object_detection/data/weights/ssd300_\" + str(epoch+1) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 1/12\n",
      "------------------------------------------------------------\n",
      "(Training)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 12\n",
    "train_model(net, dataloader_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7488c8d9eb7ed3d5151bbc22498b52a7b04b666c40ba47909f47442983d3dbb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
